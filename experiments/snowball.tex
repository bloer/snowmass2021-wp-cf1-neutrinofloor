Snowball lead: Matthew Szydagis
The snowball chamber is a nascent technology which is analogous in operational principles to superheating in bubble chambers and supersaturation in cloud chambers, except that it relies on supercooling~\cite{szydagis2021}. The first prototype was constructed by Profs. Levy and Szydagis with students at UAlbany SUNY and shown to likely be sensitive to nuclear recoils from neutrons as the radioactive calibration source, with low sensitivity to electron recoils, as in dark matter bubble chambers~\cite{PICO:2019vsc}. The detector relies on lowering the temperature of liquid water below its freezing point in a sufficiently clean and smooth container so that it becomes metastable instead of immediately solidifying. An incoming particle such as a dark matter WIMP should be able to trigger the phase transition, and potentially encode directionality as well via the intense hydrogen bonding of water. One advantage of this technique would be the potential for sub-keV energy threshold; that is based however on theoretical models from atmospheric chemistry, and the precise value of the threshold still needs to be established through a rigorous calibration campaign. Another advantage is the use of water for scalability, ease of purification, background neutron moderation, and excellent spin-dependent-proton sensitivity due to the presence of hydrogen, which in turn leads to GeV-scale WIMP mass sensitivity and a lower effective neutrino fog due to the low weak charge of the proton. The presence of oxygen may enable a multi-elemental signature in the event of a discovery, for O(10 GeV/c$^2$) masses. If the threshold is indeed as low as claimed for decades for supercooled water in atmospheric sciences, then even only a few kg deployed underground for only a few years could lead to world-leading sub-GeV limits for both the standard SI and SD-proton operators.

In order for this detector technology to become viable, numerous challenges will need to be overcome, but they are anticipated to be easily solvable given sufficient funding. The water volume will need to be sufficiently purified in order to achieve a low energy threshold by lowering the temperature sufficiently without nucleation sites present, but as with a smooth container wall, the existing technologies are sufficient, with the same filtration used for the large water-based neutrino detectors, and containers sourced by superheating experiments. Reduction in background nucleation through these mitigations, combined with faster reheating methods post-event, should lead to the required livetime of $>$50\%. Another promising R\&D avenue is modularity, potentially all the way down to the level of supercooled droplets (akin to superheated droplets: e.g., PICASSO). Calibrations of all backgrounds from all sources will need to be performed, using betas and gamma-rays to fully characterize the electronic recoil discrimination power, as well as alphas to determine how much Radon contamination would be an issue. These calibrations would need to be performed as a function of temperature (and pressure) with the goal of finding a “sweet spot” temperature neither too high (high energy threshold) nor too low (low threshold) where there is low threshold and high efficiency for NR-triggered nucleation but little to no ER. Based on existing modeling and on analogies with bubble chambers, this should indeed be possible for the snowball chamber, but of course this is not guaranteed.

The required resources for construction would be at least one dedicated postdoc and one dedicated PhD graduate student, both of whom would not be splitting time with other larger projects for example which already exist and are funded. Most of the materials, equipment, and supplies exist already through earlier seed-funding initiatives, even for building a larger-scale (only grams tested thus far) viable dark matter experiment that is ready for underground deployment. As such, with person-power being the primary consideration then, an estimated \$100k/year for ~3-5 years primarily in postdoc and student salaries with fringe/overhead included, should be sufficient for getting a real dark matter experiment off the ground (or rather, under) by $\sim$2030. However, to accomplish this, the funding agencies will need to take a risk on a new idea that is not only an extrapolation from existing concepts. The cost is low so the risk is low, but the return high, based on the advantages discussed earlier. Willingness must exist for breaking out of the “chicken-egg” cycle of “no results due to funding, but no funding due to insufficient results.” With any non-zero level of funds at all, even more ideas could be explored, such as adding scintillation for energy reconstruction, via water-based liquid scintillator for instance, or use of a noble element instead of water. Given the extreme similarities in terms of the technical challenges and science goals, mergers with PICO (already a merger of PICASSO with COUPP) and SBC in the future make good sense, for pooling of resources both in terms of cost and personnel, should all of the listed parties be willing. Part of the challenge will be the existing lack of almost any funding for PICO in the United States, as it is now primarily a Canadian experiment.


